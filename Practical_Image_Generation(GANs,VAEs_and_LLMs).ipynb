{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4T_AW9E6CP8"
      },
      "source": [
        "Applications of Image Generation\n",
        "\n",
        "  1) Image inpainting\n",
        "  2) Image editing (eg., removing person in background)\n",
        "  3) Text-to-Image generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgSWcaYV6v0M"
      },
      "source": [
        "Applications of Text Generation\n",
        "\n",
        "  1) AI assistants\n",
        "  2) Synthetic training data generation\n",
        "  3) Cleaning up text drafts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GANs (Generative Adversial Networks) --> are a class of deep learning models used to generate new realistic data (image,text e.t.c) that looks like real data.\n",
        "\n",
        "Mainly Works based on ADVERSIAL LEARNING\n",
        "\n",
        "A GAN has two neural networks that compete with each other :\n",
        "\n",
        "    1) Generator(G) - Creates fake data from a random noise (Goal is fool the discriminator)\n",
        "    2) Discriminator(D) - Tries to identify whether data is real or fake (Goal is to catch the generator's fakes)\n",
        "\n",
        "Generator improves to make realistic data. Discriminator improves to identify fakes. Eventually generator becomes very good.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GANs Training process :\n",
        "\n",
        "    1) Sample random noise z\n",
        "    2) Generator creates a fake data G(z)\n",
        "    3) Discriminator sees: Real data → should output Real (1), Fake data → should output Fake (0)\n",
        "    4) Losses are computed: Discriminator learns to classify better, Generator learns to fool discriminator\n",
        "    5) Repeat until generator outputs realistic samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Common GAN Problems :\n",
        "\n",
        "    1) Mode collapse → Generator produces limited variety\n",
        "    2) Training instability → Hard to balance G and D\n",
        "    3) Vanishing gradients → Discriminator too strong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DCGAN :\n",
        "\n",
        "DCGAN is a GAN architecture specialized for images, where both Generator and Discriminator are built using Convolutional Neural Networks (CNNs)\n",
        "\n",
        "DCGAN improvements :\n",
        "\n",
        "    1) Uses CNNs → learns spatial patterns\n",
        "    2) Removes pooling layers\n",
        "    3) Enforces architectural rules → stable training\n",
        "    4) Produces high-quality images\n",
        "\n",
        "DCGAN follows strict architectural constraints :\n",
        "\n",
        "    1) No pooling layers - Learn downsampling\n",
        "    2) Strided convolutions - Better feature learning\n",
        "    3) No fully connected layers (except start/end) - Preserve spatial structure\n",
        "    4) Batch Normalization - Stable training\n",
        "    5) ReLU (Generator) - Non-linearity\n",
        "    6) LeakyReLU (Discriminator) - Avoid dead neurons\n",
        "    7) Tanh output - Stable image scaling\n",
        "\n",
        "Why CNNs Help in DCGAN ?\n",
        "\n",
        "CNNs learn :\n",
        "\n",
        "    1) Edges\n",
        "    2) Shapes\n",
        "    3) Textures\n",
        "    4) Hierarchical features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Progressive GANs :\n",
        "\n",
        "Progressive GANs are an advanced GAN training technique where image resolution is increased gradually during training, instead of training on full-resolution images from the start.\n",
        "\n",
        "Instead of directly generating a 1024×1024 image, the GAN learns in stages: eg -> 4×4 → 8×8 → 16×16 → 32×32 → ... → High resolution\n",
        "\n",
        "At each stage:\n",
        "\n",
        "    1) New layers are added\n",
        "    2) Old layers remain\n",
        "    3) Training stays stable\n",
        "\n",
        "Problems with High-Resolution GANs :\n",
        "\n",
        "    1) Training collapses easily\n",
        "    2) Generator fails to learn global structure\n",
        "    3) Discriminator becomes too strong\n",
        "    4) Extremely slow convergence\n",
        "\n",
        "Progressive GAN Solution :\n",
        "\n",
        "    1) Learn coarse features first (shapes, layout)\n",
        "    2) Add fine details later (texture, wrinkles, hair)\n",
        "    3) Stabilize adversarial training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "VAE (Variational Auto Encoder) --> is a generative model that learns how data is distributed and can generate new, similar data by sampling from a learned latent space.\n",
        "\n",
        "Why VAE's exist -> \n",
        "    Traditional autoencoders:\n",
        "        1) Compress → reconstruct\n",
        "        2) Cannot reliably generate new data\n",
        "        3) Latent space is unstructured\n",
        "\n",
        "    VAEs fix this by:\n",
        "        1) Learning a probabilistic latent space\n",
        "        2) Enforcing structure using probability distributions\n",
        "        3) Enabling sampling & generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A VAE has two main networks :\n",
        "\n",
        "    1) Encoder (Inference Network) \n",
        "    2) Decoder (Generative Network) \n",
        "\n",
        "VAE is a probabilistic generative model\n",
        "\n",
        "Encoder outputs μ and σ\n",
        "\n",
        "Uses reparameterization trick\n",
        "\n",
        "Loss = reconstruction + KL divergence\n",
        "\n",
        "Enables smooth latent space sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "VQ-VAE (Vector Quantized Variational AutoEncoder) --> is a hybrid generative model that combines ideas from VAEs and discrete latent representations.\n",
        "\n",
        "VQ-VAE has three main components:\n",
        "\n",
        "    1) Encoder\n",
        "\n",
        "    2) Vector Quantization (Codebook)\n",
        "\n",
        "    3) Decoder\n",
        "\n",
        "VQ-VAE learns discrete latent representations\n",
        "\n",
        "Uses a codebook of embeddings\n",
        "\n",
        "No KL-divergence\n",
        "\n",
        "Produces better structure & sharper outputs\n",
        "\n",
        "Often combined with Transformers for generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNyxZRe6cGR7TLweAiFJloX",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
